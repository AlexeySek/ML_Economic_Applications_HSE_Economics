{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алексей Сек, БЭК182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: importing packages and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing packages\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.linalg as spla\n",
    "import scipy.optimize as spopt\n",
    "import scipy.stats as spst\n",
    "import numpy as np\n",
    "import numpy.linalg as npla\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import Ridge as Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample dataset\n",
    "import statsmodels.api as sm\n",
    "dat = sm.datasets.get_rdataset(\"Guerry\", \"HistData\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "smfOLS = sm.regression.linear_model.OLS.from_formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 23)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important: I left comments in the code + Added markdowns starting with \"Steps:\" for my notes about the solution\n",
    "\n",
    "Also I copied useful markdowns from the seminar, hopefully, this won't be trated as plagiat :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 (2 points).\n",
    "Write a function assignment_1 that replicates the outcome of assignment_1_true on the *dat* dataset from the beginning of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment_1_true(formula, data):\n",
    "    \n",
    "    fit = smfOLS(formula, data = data).fit()\n",
    "    \n",
    "    return fit.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-6.027115</td>\n",
       "      <td>41.046645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literacy</th>\n",
       "      <td>-0.479342</td>\n",
       "      <td>0.179528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donations</th>\n",
       "      <td>-0.000675</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infants</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wealth</th>\n",
       "      <td>0.096173</td>\n",
       "      <td>0.516922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commerce</th>\n",
       "      <td>-0.100867</td>\n",
       "      <td>0.405366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1\n",
       "Intercept -6.027115  41.046645\n",
       "Literacy  -0.479342   0.179528\n",
       "Donations -0.000675   0.000954\n",
       "Infants   -0.000005   0.001164\n",
       "Wealth     0.096173   0.516922\n",
       "Commerce  -0.100867   0.405366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_1_true('Lottery ~ Literacy + Donations + Infants + Wealth + Commerce', dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's leverage formulas from the seminar to derive Confidence Intervals\n",
    "\n",
    "- prediction for unlabeled data Z is merely $$ Z \\beta = Z (X'X)^{-1} (X'X)$$\n",
    "- confidence intervals are $$\\beta_0 = \\beta \\pm 1.96*\\sqrt{diag \\ Cov(\\beta)}, \\quad \\hat{Cov}(\\beta) = \\sigma^2 (X'X)^{-1}, \\quad \\hat \\sigma = \\frac{e'e}{n-p}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Estimate beta_hat with closed form formula for OLS regression\n",
    "2. Find variances of beta (they are located on the diagonal of covariance matrix)\n",
    "    - Firstly get e (Y - X$\\beta$)\n",
    "    - Caclulate variance (square of st.dev): X.shape[0] used to get size of X matrix\n",
    "    - Define covariance matrix and then get diagonal from it\n",
    "3. 1.96 is an estimation of t-crit when number of observations $\\rightarrow \\infty$\n",
    "    - However, we have only 86 observations, so better to define exact t_crit, so use scipy.stats package\n",
    "4. Calculate Confidence intervals using simple formula mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment_1(formula, data):\n",
    "    ycolumn = formula.split(' ~ ')[0]\n",
    "    xcolumns = formula.split(' ~ ')[1].split(' + ')\n",
    "    Y = data[ycolumn].values\n",
    "    X = data[xcolumns].values\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # my code\n",
    "    # we need to derive left and right ends of Confidence intervals     \n",
    "    \n",
    "    # actually we need firstly to find the beta_hat matrix and then calculate CIs based on it\n",
    "    beta_hat = spla.inv(X.T@X)@(X.T@Y)\n",
    "    \n",
    "    # this is derived from the formula above, also used the following article: https://web.stanford.edu/~mrosenfe/soc_meth_proj3/matrix_OLS_NYU_notes.pdf\n",
    "    e = Y - X@beta_hat\n",
    "    sigma_sq = (e@e.T)/(X.shape[0] - X.shape[1])\n",
    "    cov_beta = sigma_sq * spla.inv(X.T@X)\n",
    "    \n",
    "    # find the intervals\n",
    "    t_stat = abs(sp.stats.t.ppf(0.025,80))\n",
    "    left = beta_hat - t_stat * np.sqrt(np.diagonal(cov_beta))\n",
    "    right = beta_hat + t_stat * np.sqrt(np.diagonal(cov_beta))\n",
    "    \n",
    "    # your mock results\n",
    "    results = [left, right]\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    # changed code a bit because it was more convenient for me to take results (2 x 6) and then transponse to (6 x 2)    \n",
    "    df = df.T\n",
    "    df.index = np.array(['Intercept'] + xcolumns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-6.027115</td>\n",
       "      <td>41.046645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literacy</th>\n",
       "      <td>-0.479342</td>\n",
       "      <td>0.179528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donations</th>\n",
       "      <td>-0.000675</td>\n",
       "      <td>0.000954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infants</th>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wealth</th>\n",
       "      <td>0.096173</td>\n",
       "      <td>0.516922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commerce</th>\n",
       "      <td>-0.100867</td>\n",
       "      <td>0.405366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0          1\n",
       "Intercept -6.027115  41.046645\n",
       "Literacy  -0.479342   0.179528\n",
       "Donations -0.000675   0.000954\n",
       "Infants   -0.000005   0.001164\n",
       "Wealth     0.096173   0.516922\n",
       "Commerce  -0.100867   0.405366"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_1('Lottery ~ Literacy + Donations + Infants + Wealth + Commerce', dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 (3 points).\n",
    "- Write a function that finds the coefficients for the **elastic net** regularized ols with coefficients $\\lambda$ and $\\mu$ of your choice\n",
    "- This time you do not need to find the standard errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic-net - formulas from the seminar\n",
    "$$L = ||Y - X \\beta ||^2 + \\lambda ||\\beta||^2 + \\mu |\\beta|_0\\to \\min$$\n",
    "- increasing $\\lambda$ fights multicollinearity but tends to spread the coefficients evenly\n",
    "- increasing $\\mu$ tends to find corner solutions (on kinks) thus prioritizes one coefficient over another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps\n",
    "1. Define loss function\n",
    "    - For me the struggle was how to add $\\mu|\\beta|$. To get $|\\beta|$ I used numpy package (linalg.norm function)\n",
    "2. Choose any lamda and mu hyperparameters: I rook 3 and 5 correspondingly\n",
    "3. Use any global minimization function - I took example from the seminar with spopt.shgo and modified it by adding mu and lambda\n",
    "4. Results is actually a vector $\\beta$ (vector of coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# took function from the seminar for OLS and added Regularization to it\n",
    "def loss(Y, X, beta, lamda, mu):\n",
    "    z = Y - X@beta\n",
    "    return z@z.T + lamda*beta@beta.T + mu*np.linalg.norm(beta)\n",
    "# + mu*beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment_2(formula, data, lamda, mu):\n",
    "    ycolumn = formula.split(' ~ ')[0]\n",
    "    xcolumns = formula.split(' ~ ')[1].split(' + ')\n",
    "    Y = data[ycolumn].values\n",
    "    X = data[xcolumns].values\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # my code\n",
    "    # actually let's use the same code as in the seminar but add lamda and mu to it\n",
    "    covs = 6\n",
    "    bounds = [(None, None)]*covs\n",
    "    results = spopt.shgo(lambda b: loss(Y, X, b, lamda, mu), bounds).x\n",
    "    \n",
    "    \n",
    "    # your mock results\n",
    "    df = pd.DataFrame(results, columns = [0])\n",
    "    df.index = np.array(['Intercept'] + xcolumns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>8.499647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Literacy</th>\n",
       "      <td>-0.042766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Donations</th>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Infants</th>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wealth</th>\n",
       "      <td>0.315037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commerce</th>\n",
       "      <td>0.197951</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "Intercept  8.499647\n",
       "Literacy  -0.042766\n",
       "Donations  0.000161\n",
       "Infants    0.000684\n",
       "Wealth     0.315037\n",
       "Commerce   0.197951"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assignment_2('Lottery ~ Literacy + Donations + Infants + Wealth + Commerce', dat, 3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3 (5 points)\n",
    "- Write a function that finds the coefficients for the **elastic net** regularized ols with crossvalidation\n",
    "- Use number of folds of your choice\n",
    "- You do not need to find the standard errors\n",
    "- Search for $\\lambda$, $\\mu$ in the range [0,5]x[0,5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Define loss function same as for assignment 2\n",
    "2. Define a function that optimizes betas for one fold (later we will use them in a loop for k folds)\n",
    "    - After getting optimized betas we can get a metric that we want to optimize (I used SSR as in the seminar)\n",
    "3. Iterate over different combinations of mu and lambda and save the values of metric that we are minimizing (SSR)\n",
    "4. Find what mu and lamda correspond to the lowest metric value. These are optimal hyperparameters found with CV\n",
    "    - Actually it is optimization (minimization) of error by mu and lamda\n",
    "5. Take the entire dataset and run optimization of betas for elastic net with optimal mu and lamda\n",
    "    - Here we use global optimization again as far as elnet has not closed form solution\n",
    "    - Results is the vector of betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function for elastic net\n",
    "\n",
    "def loss(Y, X, beta, lamda, mu):\n",
    "    z = Y - X@beta\n",
    "    return z@z.T + lamda*beta@beta.T + mu*np.linalg.norm(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actually this is partially the code from the seminar but adjusted to elastic net\n",
    "# As far for elastic net there is no closed form solution - I used global optimization to get betas\n",
    "\n",
    "def run(lamda, mu, X, Y, kf):\n",
    "    \n",
    "    avg = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(X):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # initially betas were for Ridge, now I adjusted to elastic net\n",
    "        # important that we use X_train for beta coefficient there\n",
    "        covs = 6\n",
    "        bounds = [(None, None)]*covs\n",
    "        beta = spopt.shgo(lambda b: loss(Y_train, X_train, b, lamda, mu), bounds).x\n",
    "        \n",
    "        # important that residuals with test observations, not train ones        \n",
    "        errors = X_test@beta - Y_test\n",
    "        SSR = errors@errors.T\n",
    "        avg = avg + SSR\n",
    "        \n",
    "    # get average from all our folds\n",
    "    return avg/kf.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assignment_3(formula, data, folds = 5):\n",
    "    \n",
    "    # this code was there initially    \n",
    "    ycolumn = formula.split(' ~ ')[0]\n",
    "    xcolumns = formula.split(' ~ ')[1].split(' + ')\n",
    "    Y = data[ycolumn].values\n",
    "    X = data[xcolumns].values\n",
    "    X = sm.add_constant(X)\n",
    "    \n",
    "    # my code\n",
    "    lamdas = []\n",
    "    mus = []\n",
    "    results = []\n",
    "    \n",
    "    # fold our dataset     \n",
    "    kf = KFold(n_splits=folds)\n",
    "    \n",
    "    # iterate over different lamda and mu combinations    \n",
    "    for lamda, mu in itertools.product(np.linspace(0,5,20), np.linspace(0,5,20)):\n",
    "        results.append(run(lamda, mu, X, Y, kf))\n",
    "        lamdas.append(lamda)\n",
    "        mus.append(mu)\n",
    "    \n",
    "    # finally get optimal lamda and mu (to define it we need to check for what lamda and mu corresponds to the lowest SSR)    \n",
    "    opt_lamda = np.round(lamdas[np.argmin(results)],2)\n",
    "    opt_mu = np.round(mus[np.argmin(results)],2)\n",
    "    \n",
    "    \n",
    "    # using optimal hyperparameters we can find coefficients of the elastic net\n",
    "    # actually this is the code from assignment 2 but here we use optimal mu and lamda, not randomly chosen ones\n",
    "    covs = 6\n",
    "    bounds = [(None, None)]*covs\n",
    "    coefficients = spopt.shgo(lambda b: loss(Y, X, b, opt_lamda, opt_mu), bounds).x\n",
    "    \n",
    "    # this code was there initially\n",
    "    # your mock results\n",
    "    results = coefficients\n",
    "    \n",
    "    df = pd.DataFrame(results, columns = [0])\n",
    "    df.index = np.array(['Intercept'] + xcolumns)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-27ebe4da15ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# elastic net coefficients with optimal mu and lamda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0massignment_3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lottery ~ Literacy + Donations + Infants + Wealth + Commerce'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfolds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-276-4c6cf38eac15>\u001b[0m in \u001b[0;36massignment_3\u001b[0;34m(formula, data, folds)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# iterate over different lamda and mu combinations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mlamdas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlamda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mmus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-273-4c712a985d4e>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(lamda, mu, X, Y, kf)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcovs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcovs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshgo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlamda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# important that residuals with test observations, not train ones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo.py\u001b[0m in \u001b[0;36mshgo\u001b[0;34m(func, bounds, args, constraints, n, iters, callback, minimizer_kwargs, options, sampling_method)\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;31m# Run the algorithm, process results and test success\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 421\u001b[0;31m     \u001b[0mshc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_routine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo.py\u001b[0m in \u001b[0;36mconstruct_complex\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0;31m# Iterate complex, process minimisers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo.py\u001b[0m in \u001b[0;36miterate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;31m# Build minimizer pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo.py\u001b[0m in \u001b[0;36miterate_hypercube\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_sampled\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0;31m# Initial triangulation of the hyper-rectangle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m             self.HC = Complex(self.dim, self.func, self.args,\n\u001b[0m\u001b[1;32m    889\u001b[0m                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymmetry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_cons\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                               self.g_args)\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dim, func, func_args, symmetry, bounds, g_cons, g_args)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Generate n-cube here:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_cube\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymmetry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msymmetry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# TODO: Assign functions to a the complex instead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mn_cube\u001b[0;34m(self, dim, symmetry, printout)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mi_parents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprintout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mperm\u001b[0;34m(self, i_parents, x_parents, xi)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Permutate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi2_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperm_symmetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mperm\u001b[0;34m(self, i_parents, x_parents, xi)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Permutate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi2_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperm_symmetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mperm\u001b[0;34m(self, i_parents, x_parents, xi)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Permutate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi2_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperm_symmetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mperm\u001b[0;34m(self, i_parents, x_parents, xi)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;31m# Permutate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi2_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mperm_symmetry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_parents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36mperm\u001b[0;34m(self, i_parents, x_parents, xi)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mxi2_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxi2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0;31m# Append to cell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_vertex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxi2_t\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0;31m# Connect neighbors and vice versa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;31m# Parent point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/scipy/optimize/_shgo_lib/triangulation.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, x, indexed)\u001b[0m\n\u001b[1;32m    628\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mindexed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# elastic net coefficients with optimal mu and lamda\n",
    "assignment_3('Lottery ~ Literacy + Donations + Infants + Wealth + Commerce', dat, folds = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 (5 points).\n",
    "- Write a function that finds the coefficients for the **ridge** regularized ols with coefficient $\\lambda$ crossvalidated\n",
    "- This time you HAVE TO to find the standard errors\n",
    "- Derive the standard errors in markdown, assuming homoskedasticity of errors $E[ee'|X]=\\sigma^2 I$\n",
    "- see, for example, https://lukesonnet.com/teaching/inference/200d_standard_errors.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I could not manage with completing this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
